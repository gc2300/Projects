{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I work in the marketing department and my product manager has asked me to get back to her some project ideas on how to improve __email click-through-rate__. That is, the company has been sending marketing emails and they want to increase __the percentage of people who click on the company link inside the email__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__table 1__\n",
    "email_id, email_text, email_version, clicked\n",
    "8       , long_email, generic,       0\n",
    "9       , short_email, personalized, 1\n",
    "\n",
    "- email_id : the Id of the email that was sent. It is unique by email\n",
    "- email_text : two different versions of the email have been sent: one has “long text” (i.e. has 4 paragraphs) and one has “short text” (just two paragraphs)\n",
    "- email_version : some emails were “personalized” (i.e. they had the name of the user receiving the email in the incipit, such as “Hi John,”), while some emails were “generic” (the incipit was just “Hi,”)\n",
    "- clicked - Whether the user has clicked on the link inside the email. This is our label and, most importantly, the goal of the project is to increase this\n",
    "\n",
    "__table 2__\n",
    "email_id, hour, weekday\n",
    "9       , 14  , Thursday\n",
    "\n",
    "- hour : the local time on which the email was sent\n",
    "- weekday : the weekday on which the email was sent\n",
    "\n",
    "__table 3__\n",
    "user_id, user_country\n",
    "\n",
    "- user_country : the country where the user receiving the email is based. It comes from the user ip address when they created the account\n",
    "\n",
    "__table 4__\n",
    "user_id, user_past_purchases\n",
    "\n",
    "- user_past_purchases : how many items in the past were bought by the user receiving the email\n",
    "\n",
    "__table 5__\n",
    "user_id, email_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I will use logistic regression given that the label I am trying to predict (\"clicked\") is binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import statsmodels.api as sm\n",
    "pandas.set_option('display.max_columns', 20)\n",
    "pandas.set_option('display.width', 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/Bien/Documents/Data_Science/Project_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(data_path + \"emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>email_text</th>\n",
       "      <th>email_version</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>user_country</th>\n",
       "      <th>user_past_purchases</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>6</td>\n",
       "      <td>Monday</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>US</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>long_email</td>\n",
       "      <td>personalized</td>\n",
       "      <td>11</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>short_email</td>\n",
       "      <td>generic</td>\n",
       "      <td>8</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>UK</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   email_id   email_text email_version  hour    weekday user_country  user_past_purchases  clicked\n",
       "0         8  short_email       generic     9   Thursday           US                    3        0\n",
       "1        33   long_email  personalized     6     Monday           US                    0        0\n",
       "2        46  short_email       generic    14    Tuesday           US                    3        0\n",
       "3        49   long_email  personalized    11   Thursday           US                   10        0\n",
       "4        65  short_email       generic     8  Wednesday           UK                    3        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99950, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>user_past_purchases</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99950.000000</td>\n",
       "      <td>99950.000000</td>\n",
       "      <td>99950.000000</td>\n",
       "      <td>99950.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>498695.729065</td>\n",
       "      <td>9.059100</td>\n",
       "      <td>3.878559</td>\n",
       "      <td>0.02070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>289226.115244</td>\n",
       "      <td>4.439618</td>\n",
       "      <td>3.196324</td>\n",
       "      <td>0.14238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>246721.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>498441.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>749936.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999998.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            email_id          hour  user_past_purchases      clicked\n",
       "count   99950.000000  99950.000000         99950.000000  99950.00000\n",
       "mean   498695.729065      9.059100             3.878559      0.02070\n",
       "std    289226.115244      4.439618             3.196324      0.14238\n",
       "min         8.000000      1.000000             0.000000      0.00000\n",
       "25%    246721.500000      6.000000             1.000000      0.00000\n",
       "50%    498441.500000      9.000000             3.000000      0.00000\n",
       "75%    749936.750000     12.000000             6.000000      0.00000\n",
       "max    999998.000000     24.000000            22.000000      1.00000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the regression, we need to know which ones are the reference levels for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email_id                int64\n",
       "email_text             object\n",
       "email_version          object\n",
       "hour                    int64\n",
       "weekday                object\n",
       "user_country           object\n",
       "user_past_purchases     int64\n",
       "clicked                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the dtypes of the \"object\" columns to \"category\", so we can check and change the refence level\n",
    "data[data.select_dtypes(['object']).columns] = data[data.select_dtypes(['object']).columns].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_text       long_email\n",
      "email_version       generic\n",
      "weekday              Friday\n",
      "user_country             ES\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select the categorical variables\n",
    "data_categorical = data.select_dtypes(['category'])\n",
    "#find reference level, i.e. the first level\n",
    "print(data_categorical.apply(lambda x: x.cat.categories[0])) \n",
    "#dataframe.apply(lambda x: x) targetting on each column (x) in the dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Change the __reference level__ of a categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['long_email', 'short_email'], ordered=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['email_text'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_type = CategoricalDtype(categories=['short_email','long_email'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['email_text'] = data['email_text'].astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_text       short_email\n",
      "email_version        generic\n",
      "weekday               Friday\n",
      "user_country              ES\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_categorical = data.select_dtypes(['category'])\n",
    "print(data_categorical.apply(lambda x: x.cat.categories[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dummy variables from categorical ones. Using one-hot encoding and drop_first=True \n",
    "data = pandas.get_dummies(data, drop_first=True) # it will only get dummies for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add intercept\n",
    "data['intercept'] = 1\n",
    "#drop the label\n",
    "train_cols = data.drop('clicked', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092770\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "#Build Logistic Regression\n",
    "logit = sm.Logit(data['clicked'], train_cols)\n",
    "output = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            coefficients            SE          z       p_values\n",
      "email_id                   -3.848609e-08  7.780379e-08  -0.494656   6.208432e-01\n",
      "hour                        1.670684e-02  5.005879e-03   3.337445   8.455247e-04\n",
      "user_past_purchases         1.878107e-01  5.725787e-03  32.800855  5.725039e-236\n",
      "email_text_long_email      -2.793085e-01  4.530477e-02  -6.165101   7.043829e-10\n",
      "email_version_personalized  6.387251e-01  4.691461e-02  13.614631   3.277989e-42\n",
      "weekday_Monday              5.410326e-01  9.341014e-02   5.792011   6.954864e-09\n",
      "weekday_Saturday            2.828638e-01  9.777629e-02   2.892969   3.816190e-03\n",
      "weekday_Sunday              1.836278e-01  1.001194e-01   1.834088   6.664099e-02\n",
      "weekday_Thursday            6.254040e-01  9.233999e-02   6.772839   1.262790e-11\n",
      "weekday_Tuesday             6.162222e-01  9.237223e-02   6.671077   2.539336e-11\n",
      "weekday_Wednesday           7.554637e-01  9.084515e-02   8.315950   9.102053e-17\n",
      "user_country_FR            -7.864563e-02  1.625969e-01  -0.483685   6.286097e-01\n",
      "user_country_UK             1.155255e+00  1.220603e-01   9.464618   2.946372e-21\n",
      "user_country_US             1.141360e+00  1.159626e-01   9.842487   7.386228e-23\n",
      "intercept                  -6.601613e+00  1.549501e-01 -42.604781   0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "output_table = pandas.DataFrame(dict(coefficients = output.params, SE = output.bse, z = output.tvalues, p_values = output.pvalues))\n",
    "#get coefficients and pvalues\n",
    "print(output_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            coefficients        SE          z       p_values\n",
      "user_country_UK                 1.155255  0.122060   9.464618   2.946372e-21\n",
      "user_country_US                 1.141360  0.115963   9.842487   7.386228e-23\n",
      "weekday_Wednesday               0.755464  0.090845   8.315950   9.102053e-17\n",
      "email_version_personalized      0.638725  0.046915  13.614631   3.277989e-42\n",
      "weekday_Thursday                0.625404  0.092340   6.772839   1.262790e-11\n",
      "weekday_Tuesday                 0.616222  0.092372   6.671077   2.539336e-11\n",
      "weekday_Monday                  0.541033  0.093410   5.792011   6.954864e-09\n",
      "weekday_Saturday                0.282864  0.097776   2.892969   3.816190e-03\n",
      "user_past_purchases             0.187811  0.005726  32.800855  5.725039e-236\n",
      "hour                            0.016707  0.005006   3.337445   8.455247e-04\n",
      "email_text_long_email          -0.279308  0.045305  -6.165101   7.043829e-10\n",
      "intercept                      -6.601613  0.154950 -42.604781   0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "#only keep significant variables and order results by coefficient value\n",
    "print(output_table.loc[output_table['p_values'] < 0.05].sort_values(\"coefficients\", ascending=False))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. User country seems very important. Especially interesting is that English speaking countries (US, UK) are doing significantly better than non-English speaking countries (ES, FR). That could mean a bad translation or in general a non-localized version of the email. The first thing you want to do here is probably getting in touch with the international team and asking them to review French and Spanish email templates\n",
    "2. Not surprisingly, all weekday coefficients are positive. Sunday is (barely) non-significant, all others are significant. This is a consequence of having Friday as reference level. It is a well-known fact that sending marketing emails on Friday is not a great idea. Wednesday seems to be the best day, but in general all week days (Monday-Thursday) perform similarly. Friday - Sunday are much worse. The company should probably start sending emails only Monday-Thursday, with a particular focus on the middle of the week\n",
    "3. Personalized emails are doing better. So the company should stop sending generic emails. But most importantly, this can be a huge insight from a product standpoint. If just adding the name at the top is increasing clicks significantly, imagine what would happen with even more personalization. Definitely worth investing in this\n",
    "4. Sending short emails appears to be better, but personalizing emails should be the priority vs finding a general optimal email template that on an average works best for everyone (see much lower coefficient compared to the personalization one)\n",
    "5. Hour perfectly emphasizes the problems of logistic regressions with numerical variables. The best time is likely during the day and early mornings and late nights are probably bad. But the model is trying to find a linear relationship between hour and the output. In most cases, this means that will not find a significant relationship. If it does find significance, the results would be highly misleading. Like in this case, it is telling us that the larger the value of hour, the better it is. So the best time would be 24 (midnight)! To solve this, you should manually create segments (i.e. indicator variables) before building the model. One segment could be night time, one morning to noon, etc.\n",
    "6. Email_id is not significant, but the p-value is not that high either, so it is something to keep in mind. Email_id could be interesting because it can be seen as a proxy for time, i.e. the first email sent gets id 1, second id 2, etc. So a significant and negative coefficient would mean that as time goes by, less and less people are clicking on the email. This could be a big red flag, like for instance Google started labeling us as spam. It doesn’t look like the case here, but still, it is something to keep in mind\n",
    "7. More importantly, note the super low coefficient for email_id compared to the other ones. That doesn’t mean that the variable is irrelevant. The super low coefficient simply depends on the fact that email_id scale is way larger than the other variables. The max value of all other variables is 24 for hour. The max value of email_id is 100K! So the low coefficient is meant to balance the different scale, otherwise email_id would entirely drive the regression output.\n",
    "8. The intercept highly negative and significant is the regression outcome if all variables are set to zero. So, basically, categorical variables are all set to their reference levels and numerical variables are set to 0. Intercepts are almost always negative and significant given that in the majority of cases you are dealing with imbalanced classes, where 1s are <5% of the events. And in a logistic regression a negative outcome means higher probability of predicting class zero. Don’t read too much into it. After all, the all-values-are-0 scenario is unrealistic at best, and often impossible. Like here “hour” is coded as from 1 to 24, so it cannot even have the value 0! __Only thing, looking at the scale of the intercept vs the scale of the other coefficients * the possible values of those variables can be useful to get a sense of by how much you can affect the output__\n",
    "    1. If I send emails on Wednesday, that variable value becomes 0.7 (i.e. 0.7 coefficient times the value of the variable that would be 1) which is pretty high relative to the -6.8 intercept. So opportunities of meaningful improvements are there. Imagine my intercept were -1000 and Wednesday coefficient were the same. Then optimizing the day would be almost irrelevant from a practical standpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
